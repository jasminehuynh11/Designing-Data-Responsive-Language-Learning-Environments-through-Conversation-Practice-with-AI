{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase 1: Dialogue Preprocessing\n",
        "\n",
        "This notebook processes dialogue documents and extracts structured conversation data.\n",
        "\n",
        "## Steps:\n",
        "1. Extract text from Word/PDF documents\n",
        "2. Normalize speakers (learner/bot)\n",
        "3. Generate turn lists\n",
        "4. Save as JSON files (W1_T1.json, etc.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import json\n",
        "\n",
        "# Add scripts directory to path\n",
        "project_root = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
        "sys.path.insert(0, str(project_root / 'scripts'))\n",
        "\n",
        "from document_extractor import extract_text, save_extracted_text\n",
        "from dialogue_parser import DialogueParser\n",
        "\n",
        "print(f\"Project root: {project_root}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Extract Text from Documents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define document paths\n",
        "raw_data_dir = project_root / 'data' / 'raw'\n",
        "extracted_text_dir = project_root / 'data' / 'extracted_text'\n",
        "processed_dir = project_root / 'data' / 'processed'\n",
        "\n",
        "# Document mapping\n",
        "documents = {\n",
        "    'week1': {\n",
        "        'file': raw_data_dir / '#18. Week1.docx',\n",
        "        'format': 'week1_week2'\n",
        "    },\n",
        "    'week2': {\n",
        "        'file': raw_data_dir / '#12. Week2.docx',\n",
        "        'format': 'week1_week2'\n",
        "    },\n",
        "    'week3': {\n",
        "        'file': raw_data_dir / '#16. Week3.docx',\n",
        "        'format': 'week3'\n",
        "    },\n",
        "    'week4': {\n",
        "        'file': raw_data_dir / '#14. Week4.pdf',\n",
        "        'format': 'week4'\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"Documents to process:\")\n",
        "for week, info in documents.items():\n",
        "    exists = info['file'].exists()\n",
        "    print(f\"  {week}: {info['file'].name} - {'✓' if exists else '✗'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract text from all documents\n",
        "extracted_texts = {}\n",
        "week4_color_data = None  # Store color data for Week4\n",
        "\n",
        "from document_extractor import extract_text_with_colors_from_pdf\n",
        "\n",
        "for week, info in documents.items():\n",
        "    if not info['file'].exists():\n",
        "        print(f\"Warning: {info['file']} not found, skipping...\")\n",
        "        continue\n",
        "    \n",
        "    print(f\"\\nExtracting text from {week}...\")\n",
        "    try:\n",
        "        # Special handling for Week4 to extract color information\n",
        "        if week == 'week4':\n",
        "            try:\n",
        "                week4_color_data = extract_text_with_colors_from_pdf(str(info['file']))\n",
        "                # Also get plain text\n",
        "                text = extract_text(str(info['file']))\n",
        "                extracted_texts[week] = text\n",
        "                print(f\"  Extracted text with color information\")\n",
        "            except Exception as e:\n",
        "                print(f\"  Warning: Could not extract colors, using plain text: {e}\")\n",
        "                text = extract_text(str(info['file']))\n",
        "                extracted_texts[week] = text\n",
        "        else:\n",
        "            text = extract_text(str(info['file']))\n",
        "            extracted_texts[week] = text\n",
        "        \n",
        "        # Save extracted text\n",
        "        output_file = extracted_text_dir / f\"{week}_extracted.txt\"\n",
        "        save_extracted_text(text, str(output_file))\n",
        "        \n",
        "        print(f\"  Extracted {len(text)} characters\")\n",
        "        print(f\"  Preview (first 200 chars): {text[:200]}...\")\n",
        "    except Exception as e:\n",
        "        print(f\"  Error extracting {week}: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2 & 3: Parse Dialogues and Generate Turn Lists\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize parser\n",
        "parser = DialogueParser()\n",
        "\n",
        "# Process each week\n",
        "all_dialogues = {}\n",
        "\n",
        "for week, info in documents.items():\n",
        "    if week not in extracted_texts:\n",
        "        continue\n",
        "    \n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Processing {week.upper()}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    text = extracted_texts[week]\n",
        "    \n",
        "    # Parse based on format\n",
        "    if info['format'] == 'week1_week2':\n",
        "        turns = parser.parse_week1_week2(text)\n",
        "    elif info['format'] == 'week3':\n",
        "        turns = parser.parse_week3(text)\n",
        "    elif info['format'] == 'week4':\n",
        "        # Use color data if available\n",
        "        turns = parser.parse_week4_pdf(text, color_data=week4_color_data)\n",
        "    else:\n",
        "        print(f\"Unknown format for {week}\")\n",
        "        continue\n",
        "    \n",
        "    print(f\"\\nParsed {len(turns)} turns\")\n",
        "    \n",
        "    # Preview first few turns\n",
        "    print(\"\\nFirst 3 turns:\")\n",
        "    for turn in turns[:3]:\n",
        "        print(f\"  Turn {turn['turn']} ({turn['speaker']}): {turn['text'][:80]}...\")\n",
        "    \n",
        "    all_dialogues[week] = turns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4a: Split Dialogues into Tasks (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split dialogues into tasks and save\n",
        "saved_files = []\n",
        "\n",
        "for week, turns in all_dialogues.items():\n",
        "    if not turns:\n",
        "        print(f\"No turns found for {week}, skipping...\")\n",
        "        continue\n",
        "    \n",
        "    week_num = week.replace('week', '')\n",
        "    text = extracted_texts[week]\n",
        "    info = documents[week]  # Get document format info\n",
        "    \n",
        "    # Try to split into tasks\n",
        "    tasks = parser.split_into_tasks(text, int(week_num))\n",
        "    \n",
        "    if len(tasks) > 1:\n",
        "        print(f\"\\n{week.upper()}: Found {len(tasks)} tasks\")\n",
        "        # Parse each task separately\n",
        "        for task_idx, (task_name, task_text) in enumerate(tasks, 1):\n",
        "            # Parse the task text\n",
        "            if info['format'] == 'week1_week2':\n",
        "                task_turns = parser.parse_week1_week2(task_text)\n",
        "            elif info['format'] == 'week3':\n",
        "                task_turns = parser.parse_week3(task_text)\n",
        "            elif info['format'] == 'week4':\n",
        "                task_turns = parser.parse_week4_pdf(task_text, color_data=week4_color_data)\n",
        "            else:\n",
        "                task_turns = []\n",
        "            \n",
        "            if task_turns:\n",
        "                # Renumber turns starting from 1\n",
        "                for i, turn in enumerate(task_turns, 1):\n",
        "                    turn['turn'] = i\n",
        "                \n",
        "                output_file = processed_dir / f\"W{week_num}_T{task_idx}.json\"\n",
        "                parser.save_dialogue_json(task_turns, str(output_file))\n",
        "                saved_files.append(output_file)\n",
        "                print(f\"  Saved {output_file.name} with {len(task_turns)} turns\")\n",
        "    else:\n",
        "        # Single task - save all turns\n",
        "        output_file = processed_dir / f\"W{week_num}_T1.json\"\n",
        "        parser.save_dialogue_json(turns, str(output_file))\n",
        "        saved_files.append(output_file)\n",
        "        print(f\"\\n{week.upper()}: Saved as single task {output_file.name}\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"Summary: Saved {len(saved_files)} dialogue files\")\n",
        "print(f\"{'='*60}\")\n",
        "for f in saved_files:\n",
        "    print(f\"  {f.name}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Verification: Preview Generated JSON Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and preview one of the generated files\n",
        "if saved_files:\n",
        "    sample_file = saved_files[0]\n",
        "    print(f\"Preview of {sample_file.name}:\")\n",
        "    print(\"-\" * 60)\n",
        "    \n",
        "    with open(sample_file, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "    \n",
        "    print(f\"Total turns: {len(data)}\")\n",
        "    print(f\"\\nFirst 5 turns:\")\n",
        "    for turn in data[:5]:\n",
        "        print(f\"\\nTurn {turn['turn']} - {turn['speaker']}:\")\n",
        "        print(f\"  {turn['text']}\")\n",
        "    \n",
        "    if len(data) > 5:\n",
        "        print(f\"\\n... and {len(data) - 5} more turns\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
